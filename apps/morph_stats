#!/usr/bin/env python

# Copyright (c) 2015, Ecole Polytechnique Federale de Lausanne, Blue Brain Project
# All rights reserved.
#
# This file is part of NeuroM <https://github.com/BlueBrain/NeuroM>
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above copyright
#        notice, this list of conditions and the following disclaimer in the
#        documentation and/or other materials provided with the distribution.
#     3. Neither the name of the copyright holder nor the names of
#        its contributors may be used to endorse or promote products
#        derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

'''Examples of extracting basic statistics'''
import argparse
import json
import logging
import os
import sys
from collections import defaultdict
import yaml
import numpy as np
import neurom as nm
from neurom.io.utils import get_morph_files

L = logging.getLogger(__name__)


_CONFIG = {
    'neurite': {
        'section_lengths': ['max', 'total'],
        'section_volumes': ['total'],
        'section_branch_orders': ['max']
    },
    'neurite_type': ['AXON', 'APICAL_DENDRITE', 'BASAL_DENDRITE', 'ALL'],
    'neuron': {
        'soma_radii': ['mean']
    }
}

_NEURITE_MAP = {
    'AXON': nm.AXON,
    'BASAL_DENDRITE': nm.BASAL_DENDRITE,
    'APICAL_DENDRITE': nm.APICAL_DENDRITE,
    'ALL': nm.ANY_NEURITE
}


def parse_args():
    '''Parse command line arguments'''
    parser = argparse.ArgumentParser(description='Morphology statistics extractor',
                                     epilog='Note: Outputs json')

    parser.add_argument('datapath',
                        help='Path to a morphology data file or a directory')

    parser.add_argument('-v', '--verbose', action='count', dest='verbose', default=0,
                        help='-v for INFO, -vv for DEBUG')

    parser.add_argument('--as-population',
                        action='store_true',
                        default=False,
                        help='If enabled the directory is treated as a population')

    parser.add_argument('-C', '--config', help='Configuration File')

    parser.add_argument('-o', '--output', dest='output_file',
                        help='Summary output file name')

    return parser.parse_args()


def eval_stats(values, mode):
    '''Extract a summary statistic from an numpy array of values

    Parameters:
        values: numpy array of values
        mode: summary stat to extract. One of ['min', 'max', 'median', 'mean', 'std', 'raw']

    Note: fails silently if values is empty
    '''
    if mode == 'raw':
        return values.tolist()
    if mode == 'total':
        mode = 'sum'

    try:
        return getattr(np, mode)(values)
    except ValueError:
        pass


def _stat_name(feat_name, stat_mode):
    '''Set stat name based on feature name and stat mode'''
    if feat_name[-1] == 's':
        feat_name = feat_name[:-1]
    if feat_name == 'soma_radii':
        feat_name = 'soma_radius'
    if stat_mode == 'raw':
        return feat_name

    return '%s_%s' % (stat_mode, feat_name)


def extract_stats(neurons, config):
    '''Extract stats from neurons'''

    stats = defaultdict(dict)
    for ns, modes in config['neurite'].iteritems():
        for n in config['neurite_type']:
            n = _NEURITE_MAP[n]
            for mode in modes:
                stat_name = _stat_name(ns, mode)
                stats[n.name][stat_name] = eval_stats(nm.get(ns, neurons, neurite_type=n), mode)
                L.debug('Stat: %s, Neurite: %s, Type: %s',
                        stat_name, n, type(stats[n.name][stat_name]))

    for ns, modes in config['neuron'].iteritems():
        for mode in modes:
            stat_name = _stat_name(ns, mode)
            stats[stat_name] = eval_stats(nm.get(ns, neurons), mode)

    return stats


def _get_config(config):
    '''Load configuration from file if requested in commandline arge, else use default'''
    if config:
        try:
            with open(config, 'r') as config_file:
                return yaml.load(config_file)
        except yaml.scanner.ScannerError as e:
            L.error('Invalid yaml file : \n %s', str(e))
            sys.exit(1)
    else:
        return _CONFIG


if __name__ == '__main__':
    args = parse_args()
    logging.basicConfig(level=(logging.WARNING,
                               logging.INFO,
                               logging.DEBUG)[min(args.verbose, 2)])

    _f = args.datapath
    _results = {}
    _config = _get_config(args.config)

    if os.path.isfile(_f):
        _results[_f] = extract_stats(nm.load_neuron(_f), _config)
    elif os.path.isdir(_f):
        if not args.as_population:
            for _p in get_morph_files(_f):
                _results[_p] = extract_stats(nm.load_neuron(_p), _config)
        else:
            _results[_f] = extract_stats(nm.load_neurons(_f), _config)
    else:
        L.error("Invalid data path %s", _f)
        sys.exit(1)

    print json.dumps(_results, indent=2, separators=(',', ':'))

    if args.output_file:
        with open(args.output_file, 'w') as output_file:
            json.dump(_results, output_file)
