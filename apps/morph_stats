#!/usr/bin/env python

# Copyright (c) 2015, Ecole Polytechnique Federale de Lausanne, Blue Brain Project
# All rights reserved.
#
# This file is part of NeuroM <https://github.com/BlueBrain/NeuroM>
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above copyright
#        notice, this list of conditions and the following disclaimer in the
#        documentation and/or other materials provided with the distribution.
#     3. Neither the name of the copyright holder nor the names of
#        its contributors may be used to endorse or promote products
#        derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

'''Examples of extracting basic statistics'''
import argparse
import json
import logging
import os
import sys

from itertools import chain
import numpy as np

from neurom.core.types import NEURITES
from neurom.ezy import load_neuron, load_population
from neurom.io.utils import get_morph_files

L = logging.getLogger(__name__)


NEURITE_STATS = [
    'get_section_lengths',
    'get_segment_lengths',
    'get_local_bifurcation_angles',
    'get_remote_bifurcation_angles',
    'get_n_sections_per_neurite'
]


NEURITE_STATS_INT = [
    'get_n_sections',
    'get_n_neurites'
]


SCALAR_STATS = [
    'get_soma_radius',
    'get_soma_surface_area',
]


def parse_args():
    '''Parse command line arguments'''
    parser = argparse.ArgumentParser(description='Morphology statistics extractor',
                                     epilog='Note: Outputs json')

    parser.add_argument('datapaths',
                        nargs='+',
                        help='Paths to morphology data file or directory')

    parser.add_argument('-v', '--verbose', action='count', dest='verbose', default=0,
                        help='-v for INFO, -vv for DEBUG')

    parser.add_argument('--dir_as_pop',
                        action='store_true',
                        default=False,
                        help='If more than one directories are specified in the \
                              datapaths and this flag is enabled the cells in the \
                              will be treated a population')
    return parser.parse_args()


def calculate_stats(values):
    '''Calculate basic stats
    '''
    # check if array is empty
    if len(values) > 0:
        stats = {
            'mean': np.mean(values),
            'std': np.std(values),
            'min': np.min(values),
            'max': np.max(values),
        }
    else:
        stats = {
            'mean': 0.,
            'std': 0.,
            'min': 0.,
            'max': 0.,
        }
    return stats


def extract_neurons_stats(files):
    '''Extract stats from files'''
    results = {}
    for _f in files:
        nrn = load_neuron(_f)
        stats = results[_f] = {}
        for ns in NEURITE_STATS + NEURITE_STATS_INT:
            stat_name = ns[4:]
            stats[stat_name] = {}
            for n in NEURITES:
                value = getattr(nrn, ns)(n)
                L.debug('Stat: %s, Neurite: %s, Type: %s', ns, n, type(value))
                if isinstance(value, np.ndarray):
                    value = calculate_stats(value)
                stats[stat_name][n.name] = value

        for ns in SCALAR_STATS:
            stats[ns[4:]] = getattr(nrn, ns)()
    return results


def extract_populations_stats(files):
    '''Extract stats from directories treated as populations'''
    results = {}

    for _f in files:
        pop = load_population(_f)
        stats = results[_f] = {}
        for ns in NEURITE_STATS:
            stat_name = ns[4:]
            stats[stat_name] = {}
            for n in NEURITES:
                value = np.fromiter(chain.from_iterable(getattr(nrn, ns)(n) for nrn in pop.neurons),
                                    np.float)
                L.debug('Stat: %s, Neurite: %s, Type: %s', ns, n, type(value))
                value = calculate_stats(value)
                stats[stat_name][n.name] = value

        for ns in NEURITE_STATS_INT:
            stat_name = ns[4:]
            stats[stat_name] = {}
            for n in NEURITES:
                value = np.array([getattr(nrn, ns)(n) for nrn in pop.neurons])
                L.debug('Stat: %s, Neurite: %s, Type: %s', ns, n, type(value))
                value = calculate_stats(value)
                stats[stat_name][n.name] = value

        for ns in SCALAR_STATS:
            value = np.array([getattr(nrn, ns)() for nrn in pop.neurons])
            L.debug('Stat: %s, Neurite: %s, Type: %s', ns, n, type(value))
            value = calculate_stats(value)
            stats[stat_name][n.name] = value

    return results


if __name__ == '__main__':
    args = parse_args()
    logging.basicConfig(level=(logging.WARNING,
                               logging.INFO,
                               logging.DEBUG)[min(args.verbose, 2)])

    data_paths = args.datapaths

    # treat a directory as a population
    if args.dir_as_pop:

        _stats = extract_populations_stats(data_paths)

    # otherwise concatenate all the found files
    else:

        _files = []
        for data_path in data_paths:

            if os.path.isfile(data_path):
                _files.append(data_path)
            elif os.path.isdir(data_path):
                _files.extend(get_morph_files(data_path))
            else:
                L.error('Invalid data path %s', data_path)
                sys.exit(1)
        _stats = extract_neurons_stats(_files)

    print json.dumps(_stats, indent=2, separators=(',', ':'))
